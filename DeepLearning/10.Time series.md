 # Time series 
## Sequence Matter
<p align=center><img src = "images/image98.png" width=25%></p>

- 시간에 따라 이동하는 공의 위치 예측
    - sequece of data
        - HMM 사용하여 시계열 데이터 prediction
    - physics 에 기반하여 예측
        - kalman filter
    - deep learning
        - RNN, LSTM, ...

<br>
<br>

## Sequence
- Sentence
    - "This morning I took the dog for a walk"

- Medical signal
    <p align=center><img src = "images/image99.PNG" width=30%></p>
- speech wavefoem
    <p align=center><img src = "images/image100.PNG" width=30%></p>
- Vibration measurement
    <p align=center><img src = "images/image101.PNG" width=30%></p>

<br>
<br>

## Sequence Modeling
- 대부분의 실생활 데이터는 time-series
- 중요하게 고려할 요소
    - Past evens
    - Relations between events
        - Causality
            - 과거의 어떤 사건이 있어서 지금 현재의 일이 일어남
        - Credit assignment
    - Learning the structure and hierarchy

- 과거와 현재의 관측으로 미래를 예측

<br>
<br>

## (Deterministic) Time Series Data
- For example
    <p align=center><img src="https://latex.codecogs.com/svg.image?y[0]=1,\quad&space;y[1]=\frac{1}{2},\quad&space;y[2]=\frac{1}{4},\quad\cdots&space;" title="y[0]=1,\quad y[1]=\frac{1}{2},\quad y[2]=\frac{1}{4},\quad\cdots " /></p>

<br>

- Closedform
    <p align=center><img src="https://latex.codecogs.com/svg.image?y[n]={(\frac{1}{2})}^n,\quad&space;n&space;\geq&space;0" title="y[n]={(\frac{1}{2})}^n,\quad n \geq 0" /></p>

<br>

- Linear difference equation(LDE) and initial condition

    <p align=center><img src="https://latex.codecogs.com/svg.image?y[n]={\frac{1}{2}}{y[n-1]},&space;\quad&space;y[0]=1" title="y[n]={\frac{1}{2}}{y[n-1]}, \quad y[0]=1" /></p>
 
    - 한 시점의 과거로부터 현재의 값 예측 
<br>

- High order LEDs
    <p align=center><img src="https://latex.codecogs.com/svg.image?y[n]&space;=&space;{\alpha_1&space;y[n-1]}&space;&plus;&space;{\alpha&space;y[n-2]]}" title="y[n] = {\alpha_1 y[n-1]} + {\alpha y[n-2]]}" /></p>

    - 두 시점의 과거에서부터의 데이터로 현재의 값 예측

    <br>

    <p align=center><img src="https://latex.codecogs.com/svg.image?y[n]&space;=&space;{\alpha_1&space;y[n-1]}&space;&plus;&space;{\alpha&space;y[n-2]]}&space;&plus;&space;\cdots&space;&plus;&space;{a_ky[n-k]}" title="y[n] = {\alpha_1 y[n-1]} + {\alpha y[n-2]]} + \cdots + {a_ky[n-k]}" /></p>
    
    - k 시점의 과거에서부터의 데이터로 현재의 값 예측

<br>
<br>

## (Stochastic) Time Series Data
- Stochastic
    - Probablistic 함, noise가 있고, ..

<br>

- Stationary
    - 시간이 변해도 통계쩍 특성이 일정한 time-series 데이터
- Non-stationary
    - 시간에 따라 통계적 특성이 변함
        - 평균, 분산, 공분산 등은 시간의 함수가 될 수 없음

<br>

<p align=center><img src = "images/image102.PNG" width=40%></p>

<br>
<br>

## Dealing with Non-sationary
- **linear trends**
    <p align=center><img src = "images/image103.PNG" width=40%></p>
    
    - <img src="https://latex.codecogs.com/svg.image?y(t)&space;=&space;{at}&plus;{b}&plus;\epsilon&space;" title="y(t) = {at}+{b}+\epsilon " /> 으로 모델링
    - <img src="https://latex.codecogs.com/svg.image?y(t)&space;=&space;{at}&plus;{b}" title="y(t) = {at}+{b}" /> &nbsp;
        - deterministic 하게 setting하고 parameter estimate
    - <img src="https://latex.codecogs.com/svg.image?\epsilon&space;" title="\epsilon " />
        - noise와 uncertainty을 handling
        - stochastic 해짐
    
<p align=center></p>

<br>

- **Non-linear trends**
    <p align=center><img src = "images/image104.PNG" width=40%></p>

    - 다항식, exponential fitting

<br>

- **Seasonal trends**
    - 주기성이 있는 것

    <p align=center><img src = "images/image104.PNG" width=40%></p>

    - <img src="https://latex.codecogs.com/svg.image?\sin,&space;\cos" title="\sin, \cos" /> 으로 deterministic 한 부분 fitting

<br>

- model assumption
    <p align=center><img src = "images/image104.PNG" width=40%></p>

    <p align=center><img src="https://latex.codecogs.com/svg.image?\begin{align*}Y_t&space;&=&space;\beta_1&space;&plus;&space;\beta_2&space;Y_{t-1}&space;\\&&plus;&space;\beta_3&space;t&space;&plus;&space;\beta_4&space;t^{\beta_5}&space;\\&&plus;&space;\beta_6&space;\sin&space;\frac{2\pi}{s}t&space;&plus;&space;&space;\beta_7&space;\cos&space;\frac{2\pi}{s}t&space;\\&&plus;&space;u_t\end{align*}" title="\begin{align*}Y_t &= \beta_1 + \beta_2 Y_{t-1} \\&+ \beta_3 t + \beta_4 t^{\beta_5} \\&+ \beta_6 \sin \frac{2\pi}{s}t + \beta_7 \cos \frac{2\pi}{s}t \\&+ u_t\end{align*}" /></p>

<br>
<br>

# Marokv Process
## Sequential Process
- 대부분의 classifier들은 데이터의 sequential 한 측면들 활용하지 않음

- 시스템이 &nbsp;<img src="https://latex.codecogs.com/svg.image?N" title="N" /> 개의 discrete 한 states(or classes, categories) 
즁 하나를 가진다고 하면
    <p align=center><img src="https://latex.codecogs.com/svg.image?q_t&space;\in&space;\{S_1,S_2,\cdots,S_N\}" title="q_t \in \{S_1,S_2,\cdots,S_N\}" /></p>

<br>

- stochastic system에 관심이 있다면 state evlolution이 random하게 되어야 함
    - 어떻게 random하게 만들 것인지가 관건

- 수학적으로 정확하게 모델링했지만 계산을 할 수가 없음
    - 정확하게 조건부 확률을 알 수 없는 경우가 많음.

- joint distribution은 conditional distribution으로 분해될 수 있음
    <p align=center><img src="https://latex.codecogs.com/svg.image?p(q_0,q_1,\cdots,q_T&space;)&space;=&space;p(q_0)&space;\;&space;p(q_1&space;\mid&space;q_0)&space;\;&space;p(&space;q_2&space;\mid&space;q_1&space;q_0&space;)&space;\;&space;p(&space;q_3&space;\mid&space;q_2&space;q_1&space;q_0&space;)&space;\cdots" title="p(q_0,q_1,\cdots,q_T ) = p(q_0) \; p(q_1 \mid q_0) \; p( q_2 \mid q_1 q_0 ) \; p( q_3 \mid q_2 q_1 q_0 ) \cdots" /></p>

    - 계산이 거의 불가능

**이를 위해 Markov Chain(Process)가 나오게 됨**

<br>
<br>

## Markov Chain
- Markovian property(assumption)
    - (assumption) 다음 state는 현재의 state에만 의존, 즉 지금의 state가 다음 state를 결정하는 유일한 조건

    <p align=center><img src="https://latex.codecogs.com/svg.image?p(q_{t&plus;1}&space;\mid&space;q_t,\cdots,q_0)&space;&space;=&space;p(q_{t&plus;1}&space;\mid&space;q_t)" title="p(q_{t+1} \mid q_t,\cdots,q_0) = p(q_{t+1} \mid q_t)" /></p>

<br>

- joint distribution 다루기 쉽고 계산 가능해짐

<br>
<br>


## Markovian property
- Markkov 상태
<p align=center><img src="https://latex.codecogs.com/svg.image?p(q_{t&plus;1}&space;\mid&space;q_t,\cdots,q_0)&space;&space;=&space;p(q_{t&plus;1}&space;\mid&space;q_t)" title="p(q_{t+1} \mid q_t,\cdots,q_0) = p(q_{t+1} \mid q_t)" /></p>

<br>

- 더 명확한 표현
<p  align=center><img src="https://latex.codecogs.com/svg.image?p(q_{t&plus;1}=s_j&space;\mid&space;q_t=s_i)=&space;{p(q_{t&plus;1}=s_j&space;\mid&space;q_t=s_i,&space;any&space;\;&space;earlier\;history)" title="p(q_{t+1}=s_j \mid q_t=s_i)= {p(q_{t+1}=s_j \mid q_t=s_i, any \; earlier\;history)" /></p>

<br>

- 현재의 state는 과거로부터의 모든 relevent한 정보를 축적해서 가지고 있음

<br>
<br>

## State Transition Matrix
- Markov state가 &nbsp;<img src="https://latex.codecogs.com/svg.image?s" title="s" /> 에서 &nbsp; <img src="https://latex.codecogs.com/svg.image?s'" title="s'" />으로 변화할 때의 **state transition probability**
<p align=center><img src="https://latex.codecogs.com/svg.image?P_{ss'}&space;=&space;P\left[S_{t&plus;1}&space;=&space;s'&space;\mid&space;S_t&space;=&space;s&space;\right]" title="P_{ss'} = P\left[S_{t+1} = s' \mid S_t = s \right]" /></p>

<br>

- State transition matrix
    - 모든 상태 변화를 확률로 나타내는 행렬
    - 시간에 따라 변화하지 않고 고정

    <br>

    <p align=center><img src = "images/image107.PNG" width=40%></p>

<br>
<br>


## Definition : Markov Process
- 과거의 정보가 중요하지 않기 때문에 memoryless
- 지금 state에서 다음 state로 넘어가는데 확률 분포를 가지고 있기 때문에 random process
- **Passive stochastic behavior**
    - 정해진 확률(state transition matrix)에 따라서 다음 state로 진행

<br>

<p align=center><img src = "images/image108.PNG" width=50%></p>

<br>
<br>

