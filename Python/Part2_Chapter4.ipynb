{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 제대로 비교하기 위해 유니코드 정규화 하기\n",
    "- 유니코드에는 결합 문자 존재하기 때문에 문자열 비교 간단하지 않음\n",
    "- 앞 문자에 연결되는 발음 구별 기호는 인쇄할 때 앞 문자와 하나로 결합되어 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- U+0301은 Combining Acute Accent\n",
    "    - e 다음에 이 문자가 오면 é 만듦\n",
    "    - 유니코드에서는 \"é\" 와 \"e\\u0301\"이 동일하다고 하며 이 두 시퀸스를 동일하게 처리해야 함\n",
    "    - 하지만 **파이썬에서는** 서로 다른 두 개의 코드 포인트 시퀸스롤 보도 동일하지 않다고 판단\n",
    "    \n",
    "- unicodedata.normalize() 함수가 제공하는 유니코드 정규화를 이용해야 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unicodedata.normalize()의 첫번째 인수\n",
    "- NFC\n",
    "    - 코드 포인티를 조합해서 가장 짧은 동일한 문자열 생성\n",
    "- NFD\n",
    "    - 조합된 문자를 기본 문잗와 별로의 결합 문자로 분리\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import  normalize\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFD', s1)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFD', s1) == normalize('NFD', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 키보드는 일반적으로 결합된 문자를 입력할 수 있으므로, 사용자가 입력하는 텍스트는 기본적으로 NFC 형태\n",
    "- 안전을 보장하기 위해 파일에 저장하기 전에 **normalize('NFC', user_text)** 코드로 문자열 청소하는 것이 좋음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NFC에 의해 다른 문자 하나로 정규화되는 문자 있음\n",
    "    - 전기저항을 나타내는 옴 기호는 그리스어 대문자 오메가로 정규화됨\n",
    "    - 겉모습은 똑같지만 다르다고 판단되므로 정규화해서 뜻하지 않은 문제 예방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OHM SIGN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "ohm = \"\\u2126\"\n",
    "name(ohm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK CAPITAL LETTER OMEGA'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm_c = normalize('NFC', ohm)\n",
    "name(ohm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NFKC, NFKD에서 k는 호환성(compatibility)를 의미\n",
    "    - 정규화의 더 강력한 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize, name\n",
    "half = \"½\" # ㅊ+한자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 케이스 폴딩\n",
    "- 기본적으로 모든 텍스트를 소문자로 변환하는 연산, 얀갼의 벼놘을 동반\n",
    "- python s.s에 추가되 str.casefold() 매서드 이용\n",
    "\n",
    "<br>\n",
    "\n",
    "- latin1 문자만 담고 있는 문자열 s의 경우 s.casecade와 s.lower()을 실행한 결과과 동일 \n",
    "- 아래의 예시는 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'µ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\u00B5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MICRO SIGN'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'µ' # \"\\u00B5\"\n",
    "name(micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK SMALL LETTER MU'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_cf = micro.casefold()\n",
    "name(micro_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('µ', 'μ')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro, micro_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ß'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\u00DF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER SHARP S'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett = 'ß' # u\"\\u00DF\"\n",
    "name(eszett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ß', 'ss')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett_cv = eszett.casefold()\n",
    "eszett, eszett_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python 3.4에서는 str.casefold와 str.lower()가 서로 다른 문자를 반환하는 코드 포인트 116개 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 정규화된 텍스트 매칭을 위한 유틸리티 함수\n",
    "- NFC, NFD 안전하며 유니코드 문자열을 적절히 비교할 수 있게 해줌\n",
    "- NFC는 대부분 애플리케이션에서 사용할 수 있는 최고의 정규화된 형태\n",
    "- str.casefold() 는 대소문자 구분 없이 문자를 비교할 때 가장 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize(\"NFC\", str1) == normalize(\"NFC\",str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize(\"NFC\", str1).casefold() == normalize(\"NFC\", str2).casefold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(\"A\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = \"Straße\"\n",
    "s4 = \"Strasse\"\n",
    "\n",
    "s3 == s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(\"A\", \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 극단적인 \"정규화\" : 바음 구별 기호 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \n",
    "    norm_txt = unicodedata.normalize(\"NFD\", txt)\n",
    "    print(\"norm_txt : \", norm_txt)\n",
    "    shaved = \"\".join(c for c in norm_txt\n",
    "                        if not unicodedata.combining(c))\n",
    "    print([c for c in norm_txt ])\n",
    "    print([c for c in norm_txt if not unicodedata.combining(c)])\n",
    "    \n",
    "    return unicodedata.normalize(\"NFC\", shaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_txt :  “Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”\n",
      "['“', 'H', 'e', 'r', 'r', ' ', 'V', 'o', 'ß', ':', ' ', '•', ' ', '½', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'Œ', 't', 'k', 'e', 'r', '™', ' ', 'c', 'a', 'f', 'f', 'e', '̀', ' ', 'l', 'a', 't', 't', 'e', ' ', '•', ' ', 'b', 'o', 'w', 'l', ' ', 'o', 'f', ' ', 'a', 'c', '̧', 'a', 'i', '́', '.', '”']\n",
      "['“', 'H', 'e', 'r', 'r', ' ', 'V', 'o', 'ß', ':', ' ', '•', ' ', '½', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'Œ', 't', 'k', 'e', 'r', '™', ' ', 'c', 'a', 'f', 'f', 'e', ' ', 'l', 'a', 't', 't', 'e', ' ', '•', ' ', 'b', 'o', 'w', 'l', ' ', 'o', 'f', ' ', 'a', 'c', 'a', 'i', '.', '”']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_txt :  Ζέφυρος, Zéfiro\n",
      "['Ζ', 'ε', '́', 'φ', 'υ', 'ρ', 'ο', 'ς', ',', ' ', 'Z', 'e', '́', 'f', 'i', 'r', 'o']\n",
      "['Ζ', 'ε', 'φ', 'υ', 'ρ', 'ο', 'ς', ',', ' ', 'Z', 'e', 'f', 'i', 'r', 'o']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ζεφυρος, Zefiro'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "shave_marks(Greek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    norm_txt = unicodedata.normalize('NFD', txt) # 모든 문자를 기반 문자와 결합 표시 기호로 분리\n",
    "    latin_base = False\n",
    "    preserve = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:   # 기반 문자가 라틴 문자일 때 결합 표시기호 건너뛰기\n",
    "            continue  \n",
    "        preserve.append(c)    # 아니면 보관\n",
    "        \n",
    "        if not unicodedata.combining(c):              # 새로운 기반 문자 찾아내고 라틴 문자인지 판단\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(preserve)\n",
    "    \n",
    "    return unicodedata.normalize('NFC', shaved)   # 문자들을 결합하고 NFC 방식으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_txt :  “Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”\n",
      "['“', 'H', 'e', 'r', 'r', ' ', 'V', 'o', 'ß', ':', ' ', '•', ' ', '½', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'Œ', 't', 'k', 'e', 'r', '™', ' ', 'c', 'a', 'f', 'f', 'e', '̀', ' ', 'l', 'a', 't', 't', 'e', ' ', '•', ' ', 'b', 'o', 'w', 'l', ' ', 'o', 'f', ' ', 'a', 'c', '̧', 'a', 'i', '́', '.', '”']\n",
      "['“', 'H', 'e', 'r', 'r', ' ', 'V', 'o', 'ß', ':', ' ', '•', ' ', '½', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'Œ', 't', 'k', 'e', 'r', '™', ' ', 'c', 'a', 'f', 'f', 'e', ' ', 'l', 'a', 't', 't', 'e', ' ', '•', ' ', 'b', 'o', 'w', 'l', ' ', 'o', 'f', ' ', 'a', 'c', 'a', 'i', '.', '”']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shave_marks_latin(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_txt :  Ζέφυρος, Zéfiro\n",
      "['Ζ', 'ε', '́', 'φ', 'υ', 'ρ', 'ο', 'ς', ',', ' ', 'Z', 'e', '́', 'f', 'i', 'r', 'o']\n",
      "['Ζ', 'ε', 'φ', 'υ', 'ρ', 'ο', 'ς', ',', ' ', 'Z', 'e', 'f', 'i', 'r', 'o']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ζεφυρος, Zefiro'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "shave_marks(Greek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ζέφυρος, Zefiro'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shave_marks_latin(Greek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-17 \n",
    "- 서양 활자(타이포그래픽) 기호를 아스키로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_map = str.maketrans(\"\"\"‚ƒ„ˆ‹‘’“”•–—˜›\"\"\",  # <1>\n",
    "                           \"\"\"'f\"^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({  # <2>\n",
    "    '€': 'EUR',\n",
    "    '…': '...',\n",
    "    'Æ': 'AE',\n",
    "    'æ': 'ae',\n",
    "    'Œ': 'OE',\n",
    "    'œ': 'oe',\n",
    "    '™': '(TM)',\n",
    "    '‰': '<per mille>',\n",
    "    '†': '**',\n",
    "    '‡': '***',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)  # <3>\n",
    "\n",
    "def dewinize(txt):\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    no_marks = no_marks.replace(\"ß\", \"ss\")\n",
    "    return unicodedata.normalize(\"NFKC\", no_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "dewinize(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciize(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 유니코드 텍스트 정렬\n",
    "- python 은 문자열을 정렬 할 때 각 단어의 코드 포인트를 비교\n",
    "    - 비아스키 문자를 사용하는 경우 부적절한 결과 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'atemoia', 'açaí', 'caju', 'cajá']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이썬에서는 비아스키 텍스트는 locale.strxfrm() 함수를 이용해서 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.UTF-8'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_COLLATE, \"pt_BR.UTF-8\") # setlocale(LC_COLLATE, <지역언어>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits, key=locale.strxfrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유니코드 대조 알고리즘을 이용한 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyuca\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "sorted_fruits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 유니코드 데이터 베이스\n",
    "- 유니코드 표준은 수많은 구조화된 텍스트 파일의 형태로 하나의 완전한 데이터베이스를 제공\n",
    "    - 이 데이터베이스에는 코드 포인트를 문자명으로 매핑하는 테이블 뿐만이 아니라 각 문자에 대한 메티데이터 및 각 문자의 연관 방법을 담음\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-21\n",
    "- 유니코드 데이터베이스 수치형 문자 메타 데이터 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r\"\\d\")\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample:\n",
    "    print(f'U+{ord(char):04x}',                       \n",
    "          char.center(6),                             # 길이가 6인 str의 중앙에 놓인 문자\n",
    "          're_dig' if re_digit.match(char) else '-',  # r\"\\d\" 정규표현식과 일치하는 문자의 걍우 re_dig 표시\n",
    "          'isdig' if char.isdigit() else '-',         # char.isdigit()가 참이면 isdig 표시\n",
    "          'isnum' if char.isnumeric() else '-',       # char.isnumeric() 참이면 isnum 표시\n",
    "          f'{unicodedata.numeric(char):5.2f}',        # 전체 너비는 5칸이며 소수점 2자리까지 포맷한 숫자값\n",
    "          unicodedata.name(char),                     # 유니코드 문자명\n",
    "          sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 이중 모드 str 및 bytes API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9.1 정규표현식에서의 str과 bytes\n",
    "- bytes로 정규표현식을 만들면 \\d, \\w 같은 패턴은 아스키 문자만 매칭\n",
    "- str로 이 패턴을 만들면 아스키 문자외에 유니코드 숫자나 문자도 매칭\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "  'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      "  str  : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      "  bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      "  str  : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      "  bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r'\\d+')     # str 형\n",
    "re_words_str = re.compile(r'\\w+')       # str 형\n",
    "re_numbers_bytes = re.compile(rb'\\d+')  # bytes 형\n",
    "re_words_bytes = re.compile(rb'\\w+')    # bytes 형\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"  # <3>\n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")        # <4>\n",
    "\n",
    "text_bytes = text_str.encode('utf_8')  # <5>\n",
    "\n",
    "print(f'Text\\n  {text_str!r}')\n",
    "print('Numbers')\n",
    "print('  str  :', re_numbers_str.findall(text_str))      # <6>\n",
    "print('  bytes:', re_numbers_bytes.findall(text_bytes))  # <7>\n",
    "print('Words')\n",
    "print('  str  :', re_words_str.findall(text_str))        # <8>\n",
    "print('  bytes:', re_words_bytes.findall(text_bytes))    # <9>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9.2 os 모듈 함수에서 str과 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 4-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1_1.py',\n",
       " '1_2.py',\n",
       " '2_1.py',\n",
       " '2_3.py',\n",
       " '2_4.py',\n",
       " '2_5.py',\n",
       " '2_6.py',\n",
       " '2_py',\n",
       " '4.6~.ipynb']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'.ipynb_checkpoints',\n",
       " b'1_1.py',\n",
       " b'1_2.py',\n",
       " b'2_1.py',\n",
       " b'2_3.py',\n",
       " b'2_4.py',\n",
       " b'2_5.py',\n",
       " b'2_6.py',\n",
       " b'2_py',\n",
       " b'4.6~.ipynb']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(b\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
