{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    \n",
    "    #i__init__ : initialize method\n",
    "    # __이름__() : dundu / magic(special) method\n",
    "    def __init__(self, name, age = 30): #  매직메소드\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "    \n",
    "    def __str__(self): #  매직메소드\n",
    "        return self.name\n",
    "    \n",
    "    def __call__(self): # 매직메소드\n",
    "        # 객체를 함수처럼 사용 할 수 있게 해줌\n",
    "        print(\"__call__\", self.name, self.name)\n",
    "        return self.age+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홍길동\n",
      "홍길동\n",
      "홍길동\n",
      "__call__ 홍길동 홍길동\n",
      "80\n",
      "__call__ 홍길동 홍길동\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Person(\"홍길동\")\n",
    "print(p.name)\n",
    "print(p)\n",
    "print(str(p))\n",
    "print(p())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'홍길동'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(p) # Person class의 객체인 경우ㅡ\n",
    "# value -> 문자열,\n",
    "# value가 객체일 경우 __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential 모델 \n",
    "- 각 Layer들의 입력과 출력이 하나라고 가정 \n",
    "- 각각의 Layer(입력층, 은닉층, 출력층)들을 차례대로 쌓아 구성\n",
    "- 다양한 구조의 네트워크를 만드는데 한계가 있다.\n",
    "\n",
    "# Functional API\n",
    "- 함수형 API를 사용하면 **다중입력, 다중출력, 그래프 형태**의 다양한 형태의 모델을 유연하게 구성 가능\n",
    "- Functional API는 직접 텐서들의 입출력을 다룸 \n",
    "- 함수호출처럼 Layer를 이용하여 입력 텐서(Input Tensor)를 입력 받고 그 결과를 출력 텐서(Output Tensor)로 반환하는 형식으로 모델 구현\n",
    "\n",
    "\n",
    "```\n",
    "input_tensor = Input(shape=(16,))\n",
    "dense = layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(32, activation='sigmoid')(dense)\n",
    "\n",
    "model = models.Model(input_tensor, output_tensor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer 구조 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 레이어들의 구조를 먼저 구성\n",
    "# 출력 변수들은 통일, 일반적으로 block 단위로 동일한 변수명 사용\n",
    "\n",
    "input_tensor = layers.Input(shape=(32, 32, 3)) # input layer는 입력을 지정하지 않는다. (model.predict(입력))\n",
    "\n",
    "x1 = layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation = \"relu\")(input_tensor)\n",
    "x1 = layers.MaxPooling2D(padding=\"same\")(x1)\n",
    "\n",
    "x2 = layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")(x1)\n",
    "x2 = layers.MaxPooling2D(padding=\"same\")(x2)\n",
    "\n",
    "x3 = layers.Flatten()(x2)\n",
    "x3 = layers.Dense(units=8, activation=\"relu\")(x3)\n",
    "\n",
    "output_tensor = layers.Dense(units=1, activation=\"sigmoid\")(x3)\n",
    "\n",
    "# 보통 중간 단계를 쓸 일이 없으면 이렇게 block 당 같은 이름으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어들의 구조를 먼저 만듦\n",
    "# 출력 변수들은 통일, 일반적으로 block 단위로 동일한 변수명 사용\n",
    "\n",
    "# trainable 설정\n",
    "input_tensor = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "conv_layer = layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")\n",
    "conv_layer.trainable = False\n",
    "\n",
    "x1 = conv_layer(input_tensor)\n",
    "x1 = layers.MaxPooling2D(padding=\"same\")(x1)\n",
    "\n",
    "x2 = layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")(x1)\n",
    "x2 = layers.MaxPooling2D(padding=\"same\")(x2)\n",
    "\n",
    "x3 = layers.Flatten()(x2)\n",
    "x3 = layers.Dense(units=8, activation=\"relu\")(x3)\n",
    "\n",
    "output_tensor = layers.Dense(units=1, activation = \"sigmoid\")(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 8200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 10,977\n",
      "Trainable params: 10,529\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fn_model = models.Model(input_tensor, output_tensor) # (입력 tensor, 출력 tensor)\n",
    "fn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일, 모델 학습, 평가, 추론은 동일\n",
    "#### 모델을 만드는 방식이 다름\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 7s 0us/step\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 2244, 224, 3)]    0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 레이어 만들기\n",
    "\n",
    "conv_base = VGG16(include_top = False)\n",
    "\n",
    "input_tensor = layers.Input(shape=(2244, 224, 3))\n",
    "x = conv_base(input_tensor)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "output_tensor = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# 모델 설정\n",
    "model = models.Model(input_tensor, output_tensor)\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이어를 합치는 함수\n",
    "- concatenate(list, axis=-1)\n",
    "    - 레이어들을 합친다\n",
    "    - list: 합칠 레이어들을 리스트에 묶어 전달\n",
    "    - axis: 합칠 기준축. (기본값: -1 : 마지막 축기준)\n",
    "- add(list), substract(list), multiply(list)\n",
    "    - 같은 index의 값들을 계산해서(더하기, 빼기, 곱하기) 하나의 레이어로 만든다.\n",
    "    - list: 합칠 레이어들을 리스트에 묶어 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet의 residual block\n",
    "\n",
    "input_tensor = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_tensor)\n",
    "\n",
    "x1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.ReLU()(x1)\n",
    "\n",
    "x2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x1)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "\n",
    "# input_tensor(입력), x2(block의 출력)을 더함\n",
    "\n",
    "add_result = layers.add([x, x2])\n",
    "\n",
    "output_tensor = layers.ReLU()(add_result)\n",
    "\n",
    "rb_model = models.Model(input_tensor, output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   1792        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 64)   36928       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 76,160\n",
      "Trainable params: 75,904\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(rb_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 출력 모델\n",
    "- 가정\n",
    "    - iris 데이터셋에서 꽃받침의 너비와 높이로 꽃입의 너비, 높이, 꽃 종류를 예측하는 모델\n",
    "    - 출력결과가 3개(꽃입의 너비, 높이, 꽃 종류)\n",
    "- X: 꽃받침 너비, 높이\n",
    "- y: 꽃잎 너비, 높이, 꽃 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "# print(X.shape, y. shape)\n",
    "\n",
    "y1 = X[:, 2]\n",
    "y2 = X[:, 3]\n",
    "y3 = y\n",
    "\n",
    "X = X[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(2,))\n",
    "\n",
    "x = layers.Dense(units=16, activation=\"relu\")(input_tensor)\n",
    "x = layers.Dense(units=8, activation=\"relu\")(x)\n",
    "\n",
    "output_1 = layers.Dense(units=1, name = \"petal_width_output\")(x) # 꽃잎 너비(연속형) : 회귀 : units : 1 ,activation : None\n",
    "output_2 = layers.Dense(units=1, name = \"petal_length_output\")(x)\n",
    "output_3 = layers.Dense(units=3, activation = \"softmax\", name=\"species_output\")(x) # 종류(범주형 - 다중분류) : units : class 개수, activation : softmax\n",
    "\n",
    "\n",
    "model = models.Model(input_tensor, [output_1, output_2, output_3]) # input, output이 여러개일 경우 List로 묶어서 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           48          input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "petal_width_output (Dense)      (None, 1)            9           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "petal_length_output (Dense)     (None, 1)            9           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "species_output (Dense)          (None, 3)            27          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 229\n",
      "Trainable params: 229\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\",\n",
    "             loss = [\"mse\", \"mse\", \"sparse_categorical_crossentropy\"] # 출력(예측) 결과 3개에 대한 각각의 loss 함수를 리스트로 묶어서 전달 \n",
    "             )\n",
    "\n",
    "# \"sparse_categorical_crossentropy\" : y(정답)을 one-hot-encoding을 내부적으로 처리 후 오차계산을 해줌\n",
    "# 3개의 오차를 더해서 total loss를 계산한 뒤 total loss 를 기반으로 역전파해서 파라미터들을 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 153ms/step - loss: 16.4455 - petal_width_output_loss: 10.1624 - petal_length_output_loss: 5.1245 - species_output_loss: 1.1585 - val_loss: 29.8194 - val_petal_width_output_loss: 18.8791 - val_petal_length_output_loss: 10.2883 - val_species_output_loss: 0.6520\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.6795 - petal_width_output_loss: 9.6226 - petal_length_output_loss: 4.8946 - species_output_loss: 1.1624 - val_loss: 28.5098 - val_petal_width_output_loss: 17.9560 - val_petal_length_output_loss: 9.9060 - val_species_output_loss: 0.6478\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.9324 - petal_width_output_loss: 9.1002 - petal_length_output_loss: 4.6649 - species_output_loss: 1.1674 - val_loss: 27.1639 - val_petal_width_output_loss: 16.9916 - val_petal_length_output_loss: 9.5307 - val_species_output_loss: 0.6416\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.1695 - petal_width_output_loss: 8.5588 - petal_length_output_loss: 4.4377 - species_output_loss: 1.1730 - val_loss: 25.8163 - val_petal_width_output_loss: 16.0283 - val_petal_length_output_loss: 9.1535 - val_species_output_loss: 0.6346\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.4138 - petal_width_output_loss: 8.0287 - petal_length_output_loss: 4.2066 - species_output_loss: 1.1785 - val_loss: 24.4532 - val_petal_width_output_loss: 15.0609 - val_petal_length_output_loss: 8.7645 - val_species_output_loss: 0.6277\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.6659 - petal_width_output_loss: 7.5036 - petal_length_output_loss: 3.9789 - species_output_loss: 1.1834 - val_loss: 23.0978 - val_petal_width_output_loss: 14.1011 - val_petal_length_output_loss: 8.3761 - val_species_output_loss: 0.6205\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9207 - petal_width_output_loss: 6.9794 - petal_length_output_loss: 3.7533 - species_output_loss: 1.1880 - val_loss: 21.7482 - val_petal_width_output_loss: 13.1331 - val_petal_length_output_loss: 8.0007 - val_species_output_loss: 0.6143\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2143 - petal_width_output_loss: 6.4794 - petal_length_output_loss: 3.5424 - species_output_loss: 1.1926 - val_loss: 20.4021 - val_petal_width_output_loss: 12.1504 - val_petal_length_output_loss: 7.6428 - val_species_output_loss: 0.6088\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5123 - petal_width_output_loss: 5.9801 - petal_length_output_loss: 3.3357 - species_output_loss: 1.1965 - val_loss: 19.0716 - val_petal_width_output_loss: 11.1688 - val_petal_length_output_loss: 7.2986 - val_species_output_loss: 0.6041\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8245 - petal_width_output_loss: 5.4826 - petal_length_output_loss: 3.1402 - species_output_loss: 1.2017 - val_loss: 17.8678 - val_petal_width_output_loss: 10.2365 - val_petal_length_output_loss: 7.0318 - val_species_output_loss: 0.5994\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2446 - petal_width_output_loss: 5.0532 - petal_length_output_loss: 2.9855 - species_output_loss: 1.2059 - val_loss: 16.7395 - val_petal_width_output_loss: 9.3562 - val_petal_length_output_loss: 6.7847 - val_species_output_loss: 0.5986\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7015 - petal_width_output_loss: 4.6635 - petal_length_output_loss: 2.8281 - species_output_loss: 1.2099 - val_loss: 15.6304 - val_petal_width_output_loss: 8.5348 - val_petal_length_output_loss: 6.4916 - val_species_output_loss: 0.6040\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.1875 - petal_width_output_loss: 4.3207 - petal_length_output_loss: 2.6562 - species_output_loss: 1.2105 - val_loss: 14.5339 - val_petal_width_output_loss: 7.7529 - val_petal_length_output_loss: 6.1698 - val_species_output_loss: 0.6112\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6790 - petal_width_output_loss: 3.9981 - petal_length_output_loss: 2.4677 - species_output_loss: 1.2131 - val_loss: 13.5130 - val_petal_width_output_loss: 7.0702 - val_petal_length_output_loss: 5.8172 - val_species_output_loss: 0.6255\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2229 - petal_width_output_loss: 3.7420 - petal_length_output_loss: 2.2688 - species_output_loss: 1.2121 - val_loss: 12.6229 - val_petal_width_output_loss: 6.5335 - val_petal_length_output_loss: 5.4452 - val_species_output_loss: 0.6442\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8206 - petal_width_output_loss: 3.5442 - petal_length_output_loss: 2.0678 - species_output_loss: 1.2087 - val_loss: 11.7502 - val_petal_width_output_loss: 6.0337 - val_petal_length_output_loss: 5.0533 - val_species_output_loss: 0.6631\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4396 - petal_width_output_loss: 3.3721 - petal_length_output_loss: 1.8614 - species_output_loss: 1.2061 - val_loss: 10.9544 - val_petal_width_output_loss: 5.6129 - val_petal_length_output_loss: 4.6577 - val_species_output_loss: 0.6839\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0828 - petal_width_output_loss: 3.2217 - petal_length_output_loss: 1.6600 - species_output_loss: 1.2011 - val_loss: 10.1793 - val_petal_width_output_loss: 5.1884 - val_petal_length_output_loss: 4.2871 - val_species_output_loss: 0.7038\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7532 - petal_width_output_loss: 3.0728 - petal_length_output_loss: 1.4812 - species_output_loss: 1.1993 - val_loss: 9.3794 - val_petal_width_output_loss: 4.7150 - val_petal_length_output_loss: 3.9424 - val_species_output_loss: 0.7219\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4502 - petal_width_output_loss: 2.9312 - petal_length_output_loss: 1.3214 - species_output_loss: 1.1975 - val_loss: 8.5903 - val_petal_width_output_loss: 4.2429 - val_petal_length_output_loss: 3.6100 - val_species_output_loss: 0.7374\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1504 - petal_width_output_loss: 2.7898 - petal_length_output_loss: 1.1666 - species_output_loss: 1.1940 - val_loss: 7.9192 - val_petal_width_output_loss: 3.8790 - val_petal_length_output_loss: 3.2847 - val_species_output_loss: 0.7554\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8958 - petal_width_output_loss: 2.6812 - petal_length_output_loss: 1.0242 - species_output_loss: 1.1904 - val_loss: 7.2919 - val_petal_width_output_loss: 3.5435 - val_petal_length_output_loss: 2.9740 - val_species_output_loss: 0.7743\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6982 - petal_width_output_loss: 2.6053 - petal_length_output_loss: 0.9058 - species_output_loss: 1.1871 - val_loss: 6.7234 - val_petal_width_output_loss: 3.2451 - val_petal_length_output_loss: 2.6855 - val_species_output_loss: 0.7928\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4967 - petal_width_output_loss: 2.5241 - petal_length_output_loss: 0.7898 - species_output_loss: 1.1828 - val_loss: 6.2807 - val_petal_width_output_loss: 3.0483 - val_petal_length_output_loss: 2.4187 - val_species_output_loss: 0.8136\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3482 - petal_width_output_loss: 2.4682 - petal_length_output_loss: 0.7028 - species_output_loss: 1.1772 - val_loss: 5.7893 - val_petal_width_output_loss: 2.7779 - val_petal_length_output_loss: 2.1835 - val_species_output_loss: 0.8279\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1713 - petal_width_output_loss: 2.3838 - petal_length_output_loss: 0.6148 - species_output_loss: 1.1727 - val_loss: 5.4017 - val_petal_width_output_loss: 2.5867 - val_petal_length_output_loss: 1.9715 - val_species_output_loss: 0.8435\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0523 - petal_width_output_loss: 2.3308 - petal_length_output_loss: 0.5536 - species_output_loss: 1.1679 - val_loss: 4.9957 - val_petal_width_output_loss: 2.3531 - val_petal_length_output_loss: 1.7824 - val_species_output_loss: 0.8602\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9384 - petal_width_output_loss: 2.2737 - petal_length_output_loss: 0.4999 - species_output_loss: 1.1647 - val_loss: 4.6490 - val_petal_width_output_loss: 2.1689 - val_petal_length_output_loss: 1.6056 - val_species_output_loss: 0.8745\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.8423 - petal_width_output_loss: 2.2267 - petal_length_output_loss: 0.4547 - species_output_loss: 1.1609 - val_loss: 4.4091 - val_petal_width_output_loss: 2.0603 - val_petal_length_output_loss: 1.4576 - val_species_output_loss: 0.8912\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7687 - petal_width_output_loss: 2.1913 - petal_length_output_loss: 0.4218 - species_output_loss: 1.1555 - val_loss: 4.2449 - val_petal_width_output_loss: 2.0027 - val_petal_length_output_loss: 1.3352 - val_species_output_loss: 0.9070\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7047 - petal_width_output_loss: 2.1565 - petal_length_output_loss: 0.3989 - species_output_loss: 1.1493 - val_loss: 4.0552 - val_petal_width_output_loss: 1.8992 - val_petal_length_output_loss: 1.2405 - val_species_output_loss: 0.9155\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6495 - petal_width_output_loss: 2.1227 - petal_length_output_loss: 0.3836 - species_output_loss: 1.1432 - val_loss: 3.9021 - val_petal_width_output_loss: 1.8169 - val_petal_length_output_loss: 1.1618 - val_species_output_loss: 0.9233\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6035 - petal_width_output_loss: 2.0932 - petal_length_output_loss: 0.3734 - species_output_loss: 1.1369 - val_loss: 3.7806 - val_petal_width_output_loss: 1.7566 - val_petal_length_output_loss: 1.0935 - val_species_output_loss: 0.9306\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5646 - petal_width_output_loss: 2.0673 - petal_length_output_loss: 0.3675 - species_output_loss: 1.1298 - val_loss: 3.7027 - val_petal_width_output_loss: 1.7223 - val_petal_length_output_loss: 1.0386 - val_species_output_loss: 0.9417\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.5230 - petal_width_output_loss: 2.0381 - petal_length_output_loss: 0.3620 - species_output_loss: 1.1229 - val_loss: 3.6969 - val_petal_width_output_loss: 1.7469 - val_petal_length_output_loss: 1.0004 - val_species_output_loss: 0.9496\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4861 - petal_width_output_loss: 2.0122 - petal_length_output_loss: 0.3586 - species_output_loss: 1.1152 - val_loss: 3.7007 - val_petal_width_output_loss: 1.7669 - val_petal_length_output_loss: 0.9742 - val_species_output_loss: 0.9595\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4491 - petal_width_output_loss: 1.9840 - petal_length_output_loss: 0.3573 - species_output_loss: 1.1078 - val_loss: 3.6813 - val_petal_width_output_loss: 1.7575 - val_petal_length_output_loss: 0.9509 - val_species_output_loss: 0.9729\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4172 - petal_width_output_loss: 1.9592 - petal_length_output_loss: 0.3566 - species_output_loss: 1.1015 - val_loss: 3.6891 - val_petal_width_output_loss: 1.7709 - val_petal_length_output_loss: 0.9353 - val_species_output_loss: 0.9829\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3830 - petal_width_output_loss: 1.9320 - petal_length_output_loss: 0.3563 - species_output_loss: 1.0947 - val_loss: 3.6907 - val_petal_width_output_loss: 1.7733 - val_petal_length_output_loss: 0.9256 - val_species_output_loss: 0.9917\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3503 - petal_width_output_loss: 1.9051 - petal_length_output_loss: 0.3565 - species_output_loss: 1.0887 - val_loss: 3.6710 - val_petal_width_output_loss: 1.7524 - val_petal_length_output_loss: 0.9216 - val_species_output_loss: 0.9969\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3176 - petal_width_output_loss: 1.8781 - petal_length_output_loss: 0.3572 - species_output_loss: 1.0823 - val_loss: 3.6200 - val_petal_width_output_loss: 1.6987 - val_petal_length_output_loss: 0.9211 - val_species_output_loss: 1.0002\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2852 - petal_width_output_loss: 1.8497 - petal_length_output_loss: 0.3579 - species_output_loss: 1.0776 - val_loss: 3.5797 - val_petal_width_output_loss: 1.6528 - val_petal_length_output_loss: 0.9211 - val_species_output_loss: 1.0058\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2547 - petal_width_output_loss: 1.8229 - petal_length_output_loss: 0.3585 - species_output_loss: 1.0734 - val_loss: 3.5200 - val_petal_width_output_loss: 1.5948 - val_petal_length_output_loss: 0.9182 - val_species_output_loss: 1.0070\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2282 - petal_width_output_loss: 1.8001 - petal_length_output_loss: 0.3590 - species_output_loss: 1.0691 - val_loss: 3.4772 - val_petal_width_output_loss: 1.5526 - val_petal_length_output_loss: 0.9111 - val_species_output_loss: 1.0135\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1973 - petal_width_output_loss: 1.7725 - petal_length_output_loss: 0.3587 - species_output_loss: 1.0662 - val_loss: 3.5012 - val_petal_width_output_loss: 1.5719 - val_petal_length_output_loss: 0.9049 - val_species_output_loss: 1.0244\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1692 - petal_width_output_loss: 1.7478 - petal_length_output_loss: 0.3586 - species_output_loss: 1.0628 - val_loss: 3.4665 - val_petal_width_output_loss: 1.5371 - val_petal_length_output_loss: 0.8957 - val_species_output_loss: 1.0337\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1434 - petal_width_output_loss: 1.7246 - petal_length_output_loss: 0.3584 - species_output_loss: 1.0604 - val_loss: 3.4445 - val_petal_width_output_loss: 1.5149 - val_petal_length_output_loss: 0.8899 - val_species_output_loss: 1.0397\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1159 - petal_width_output_loss: 1.6998 - petal_length_output_loss: 0.3581 - species_output_loss: 1.0579 - val_loss: 3.4206 - val_petal_width_output_loss: 1.4942 - val_petal_length_output_loss: 0.8801 - val_species_output_loss: 1.0462\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0924 - petal_width_output_loss: 1.6785 - petal_length_output_loss: 0.3582 - species_output_loss: 1.0557 - val_loss: 3.3714 - val_petal_width_output_loss: 1.4553 - val_petal_length_output_loss: 0.8657 - val_species_output_loss: 1.0504\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0644 - petal_width_output_loss: 1.6532 - petal_length_output_loss: 0.3573 - species_output_loss: 1.0539 - val_loss: 3.4214 - val_petal_width_output_loss: 1.4992 - val_petal_length_output_loss: 0.8646 - val_species_output_loss: 1.0577\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0376 - petal_width_output_loss: 1.6286 - petal_length_output_loss: 0.3572 - species_output_loss: 1.0517 - val_loss: 3.4387 - val_petal_width_output_loss: 1.5114 - val_petal_length_output_loss: 0.8615 - val_species_output_loss: 1.0658\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.0130 - petal_width_output_loss: 1.6060 - petal_length_output_loss: 0.3569 - species_output_loss: 1.0501 - val_loss: 3.4177 - val_petal_width_output_loss: 1.4918 - val_petal_length_output_loss: 0.8558 - val_species_output_loss: 1.0702\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9891 - petal_width_output_loss: 1.5835 - petal_length_output_loss: 0.3567 - species_output_loss: 1.0488 - val_loss: 3.4096 - val_petal_width_output_loss: 1.4856 - val_petal_length_output_loss: 0.8514 - val_species_output_loss: 1.0725\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9637 - petal_width_output_loss: 1.5600 - petal_length_output_loss: 0.3564 - species_output_loss: 1.0472 - val_loss: 3.4319 - val_petal_width_output_loss: 1.5023 - val_petal_length_output_loss: 0.8485 - val_species_output_loss: 1.0810\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.9391 - petal_width_output_loss: 1.5374 - petal_length_output_loss: 0.3560 - species_output_loss: 1.0458 - val_loss: 3.4512 - val_petal_width_output_loss: 1.5129 - val_petal_length_output_loss: 0.8469 - val_species_output_loss: 1.0914\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9170 - petal_width_output_loss: 1.5165 - petal_length_output_loss: 0.3557 - species_output_loss: 1.0448 - val_loss: 3.4597 - val_petal_width_output_loss: 1.5106 - val_petal_length_output_loss: 0.8489 - val_species_output_loss: 1.1001\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8915 - petal_width_output_loss: 1.4922 - petal_length_output_loss: 0.3555 - species_output_loss: 1.0437 - val_loss: 3.4041 - val_petal_width_output_loss: 1.4515 - val_petal_length_output_loss: 0.8475 - val_species_output_loss: 1.1052\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.8663 - petal_width_output_loss: 1.4682 - petal_length_output_loss: 0.3551 - species_output_loss: 1.0430 - val_loss: 3.3290 - val_petal_width_output_loss: 1.3761 - val_petal_length_output_loss: 0.8426 - val_species_output_loss: 1.1104\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8455 - petal_width_output_loss: 1.4482 - petal_length_output_loss: 0.3549 - species_output_loss: 1.0424 - val_loss: 3.3233 - val_petal_width_output_loss: 1.3623 - val_petal_length_output_loss: 0.8421 - val_species_output_loss: 1.1189\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8209 - petal_width_output_loss: 1.4249 - petal_length_output_loss: 0.3545 - species_output_loss: 1.0415 - val_loss: 3.3556 - val_petal_width_output_loss: 1.3838 - val_petal_length_output_loss: 0.8457 - val_species_output_loss: 1.1262\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7983 - petal_width_output_loss: 1.4033 - petal_length_output_loss: 0.3542 - species_output_loss: 1.0409 - val_loss: 3.3356 - val_petal_width_output_loss: 1.3644 - val_petal_length_output_loss: 0.8432 - val_species_output_loss: 1.1279\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7776 - petal_width_output_loss: 1.3837 - petal_length_output_loss: 0.3537 - species_output_loss: 1.0402 - val_loss: 3.2039 - val_petal_width_output_loss: 1.2572 - val_petal_length_output_loss: 0.8245 - val_species_output_loss: 1.1221\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7568 - petal_width_output_loss: 1.3643 - petal_length_output_loss: 0.3525 - species_output_loss: 1.0400 - val_loss: 3.1012 - val_petal_width_output_loss: 1.1797 - val_petal_length_output_loss: 0.8043 - val_species_output_loss: 1.1171\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7396 - petal_width_output_loss: 1.3478 - petal_length_output_loss: 0.3520 - species_output_loss: 1.0398 - val_loss: 3.0658 - val_petal_width_output_loss: 1.1619 - val_petal_length_output_loss: 0.7854 - val_species_output_loss: 1.1185\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7163 - petal_width_output_loss: 1.3262 - petal_length_output_loss: 0.3507 - species_output_loss: 1.0394 - val_loss: 3.1115 - val_petal_width_output_loss: 1.2117 - val_petal_length_output_loss: 0.7773 - val_species_output_loss: 1.1225\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6918 - petal_width_output_loss: 1.3029 - petal_length_output_loss: 0.3500 - species_output_loss: 1.0389 - val_loss: 3.0957 - val_petal_width_output_loss: 1.2091 - val_petal_length_output_loss: 0.7669 - val_species_output_loss: 1.1197\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.6697 - petal_width_output_loss: 1.2824 - petal_length_output_loss: 0.3491 - species_output_loss: 1.0383 - val_loss: 3.1253 - val_petal_width_output_loss: 1.2404 - val_petal_length_output_loss: 0.7657 - val_species_output_loss: 1.1192\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6452 - petal_width_output_loss: 1.2595 - petal_length_output_loss: 0.3481 - species_output_loss: 1.0375 - val_loss: 3.1690 - val_petal_width_output_loss: 1.2791 - val_petal_length_output_loss: 0.7717 - val_species_output_loss: 1.1182\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6232 - petal_width_output_loss: 1.2394 - petal_length_output_loss: 0.3472 - species_output_loss: 1.0366 - val_loss: 3.2701 - val_petal_width_output_loss: 1.3627 - val_petal_length_output_loss: 0.7832 - val_species_output_loss: 1.1242\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6057 - petal_width_output_loss: 1.2234 - petal_length_output_loss: 0.3465 - species_output_loss: 1.0358 - val_loss: 3.3343 - val_petal_width_output_loss: 1.4112 - val_petal_length_output_loss: 0.7954 - val_species_output_loss: 1.1277\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5840 - petal_width_output_loss: 1.2035 - petal_length_output_loss: 0.3456 - species_output_loss: 1.0349 - val_loss: 3.3103 - val_petal_width_output_loss: 1.3819 - val_petal_length_output_loss: 0.7995 - val_species_output_loss: 1.1289\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5615 - petal_width_output_loss: 1.1829 - petal_length_output_loss: 0.3447 - species_output_loss: 1.0339 - val_loss: 3.3249 - val_petal_width_output_loss: 1.3851 - val_petal_length_output_loss: 0.8092 - val_species_output_loss: 1.1306\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5471 - petal_width_output_loss: 1.1685 - petal_length_output_loss: 0.3449 - species_output_loss: 1.0337 - val_loss: 3.3742 - val_petal_width_output_loss: 1.4151 - val_petal_length_output_loss: 0.8244 - val_species_output_loss: 1.1346\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5226 - petal_width_output_loss: 1.1460 - petal_length_output_loss: 0.3437 - species_output_loss: 1.0328 - val_loss: 3.3191 - val_petal_width_output_loss: 1.3582 - val_petal_length_output_loss: 0.8308 - val_species_output_loss: 1.1300\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4994 - petal_width_output_loss: 1.1240 - petal_length_output_loss: 0.3434 - species_output_loss: 1.0320 - val_loss: 3.2754 - val_petal_width_output_loss: 1.3086 - val_petal_length_output_loss: 0.8358 - val_species_output_loss: 1.1310\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4762 - petal_width_output_loss: 1.1027 - petal_length_output_loss: 0.3422 - species_output_loss: 1.0312 - val_loss: 3.2242 - val_petal_width_output_loss: 1.2571 - val_petal_length_output_loss: 0.8349 - val_species_output_loss: 1.1321\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4559 - petal_width_output_loss: 1.0844 - petal_length_output_loss: 0.3410 - species_output_loss: 1.0304 - val_loss: 3.1537 - val_petal_width_output_loss: 1.1953 - val_petal_length_output_loss: 0.8279 - val_species_output_loss: 1.1304\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4372 - petal_width_output_loss: 1.0677 - petal_length_output_loss: 0.3398 - species_output_loss: 1.0297 - val_loss: 3.0894 - val_petal_width_output_loss: 1.1449 - val_petal_length_output_loss: 0.8152 - val_species_output_loss: 1.1293\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4168 - petal_width_output_loss: 1.0502 - petal_length_output_loss: 0.3379 - species_output_loss: 1.0287 - val_loss: 3.1199 - val_petal_width_output_loss: 1.1759 - val_petal_length_output_loss: 0.8088 - val_species_output_loss: 1.1352\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3965 - petal_width_output_loss: 1.0323 - petal_length_output_loss: 0.3364 - species_output_loss: 1.0278 - val_loss: 3.0874 - val_petal_width_output_loss: 1.1482 - val_petal_length_output_loss: 0.7984 - val_species_output_loss: 1.1408\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.3777 - petal_width_output_loss: 1.0162 - petal_length_output_loss: 0.3345 - species_output_loss: 1.0270 - val_loss: 3.0875 - val_petal_width_output_loss: 1.1488 - val_petal_length_output_loss: 0.7923 - val_species_output_loss: 1.1464\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3581 - petal_width_output_loss: 0.9996 - petal_length_output_loss: 0.3328 - species_output_loss: 1.0257 - val_loss: 3.0395 - val_petal_width_output_loss: 1.1156 - val_petal_length_output_loss: 0.7797 - val_species_output_loss: 1.1442\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.3409 - petal_width_output_loss: 0.9848 - petal_length_output_loss: 0.3312 - species_output_loss: 1.0249 - val_loss: 2.9650 - val_petal_width_output_loss: 1.0631 - val_petal_length_output_loss: 0.7596 - val_species_output_loss: 1.1423\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3233 - petal_width_output_loss: 0.9702 - petal_length_output_loss: 0.3291 - species_output_loss: 1.0240 - val_loss: 2.9538 - val_petal_width_output_loss: 1.0624 - val_petal_length_output_loss: 0.7481 - val_species_output_loss: 1.1433\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.3061 - petal_width_output_loss: 0.9558 - petal_length_output_loss: 0.3274 - species_output_loss: 1.0229 - val_loss: 2.9453 - val_petal_width_output_loss: 1.0639 - val_petal_length_output_loss: 0.7392 - val_species_output_loss: 1.1422\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2870 - petal_width_output_loss: 0.9398 - petal_length_output_loss: 0.3254 - species_output_loss: 1.0218 - val_loss: 2.9655 - val_petal_width_output_loss: 1.0872 - val_petal_length_output_loss: 0.7363 - val_species_output_loss: 1.1421\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2696 - petal_width_output_loss: 0.9255 - petal_length_output_loss: 0.3235 - species_output_loss: 1.0206 - val_loss: 2.9707 - val_petal_width_output_loss: 1.0926 - val_petal_length_output_loss: 0.7366 - val_species_output_loss: 1.1415\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2521 - petal_width_output_loss: 0.9109 - petal_length_output_loss: 0.3217 - species_output_loss: 1.0196 - val_loss: 2.9637 - val_petal_width_output_loss: 1.0896 - val_petal_length_output_loss: 0.7357 - val_species_output_loss: 1.1384\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2354 - petal_width_output_loss: 0.8978 - petal_length_output_loss: 0.3195 - species_output_loss: 1.0181 - val_loss: 3.0005 - val_petal_width_output_loss: 1.1211 - val_petal_length_output_loss: 0.7366 - val_species_output_loss: 1.1428\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2168 - petal_width_output_loss: 0.8825 - petal_length_output_loss: 0.3175 - species_output_loss: 1.0167 - val_loss: 3.0026 - val_petal_width_output_loss: 1.1184 - val_petal_length_output_loss: 0.7439 - val_species_output_loss: 1.1403\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2006 - petal_width_output_loss: 0.8687 - petal_length_output_loss: 0.3165 - species_output_loss: 1.0153 - val_loss: 2.9897 - val_petal_width_output_loss: 1.1015 - val_petal_length_output_loss: 0.7554 - val_species_output_loss: 1.1328\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.1848 - petal_width_output_loss: 0.8551 - petal_length_output_loss: 0.3152 - species_output_loss: 1.0144 - val_loss: 2.8782 - val_petal_width_output_loss: 1.0102 - val_petal_length_output_loss: 0.7503 - val_species_output_loss: 1.1178\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1667 - petal_width_output_loss: 0.8399 - petal_length_output_loss: 0.3139 - species_output_loss: 1.0130 - val_loss: 2.8964 - val_petal_width_output_loss: 1.0259 - val_petal_length_output_loss: 0.7573 - val_species_output_loss: 1.1132\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.1465 - petal_width_output_loss: 0.8235 - petal_length_output_loss: 0.3115 - species_output_loss: 1.0115 - val_loss: 2.8724 - val_petal_width_output_loss: 1.0123 - val_petal_length_output_loss: 0.7510 - val_species_output_loss: 1.1092\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1312 - petal_width_output_loss: 0.8113 - petal_length_output_loss: 0.3098 - species_output_loss: 1.0102 - val_loss: 2.8300 - val_petal_width_output_loss: 0.9839 - val_petal_length_output_loss: 0.7445 - val_species_output_loss: 1.1015\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1145 - petal_width_output_loss: 0.7985 - petal_length_output_loss: 0.3074 - species_output_loss: 1.0085 - val_loss: 2.9108 - val_petal_width_output_loss: 1.0531 - val_petal_length_output_loss: 0.7535 - val_species_output_loss: 1.1042\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0973 - petal_width_output_loss: 0.7858 - petal_length_output_loss: 0.3047 - species_output_loss: 1.0068 - val_loss: 2.9609 - val_petal_width_output_loss: 1.0945 - val_petal_length_output_loss: 0.7584 - val_species_output_loss: 1.1080\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0817 - petal_width_output_loss: 0.7739 - petal_length_output_loss: 0.3026 - species_output_loss: 1.0052 - val_loss: 2.9020 - val_petal_width_output_loss: 1.0445 - val_petal_length_output_loss: 0.7462 - val_species_output_loss: 1.1113\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0639 - petal_width_output_loss: 0.7602 - petal_length_output_loss: 0.3001 - species_output_loss: 1.0037 - val_loss: 2.8808 - val_petal_width_output_loss: 1.0258 - val_petal_length_output_loss: 0.7394 - val_species_output_loss: 1.1157\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0475 - petal_width_output_loss: 0.7476 - petal_length_output_loss: 0.2979 - species_output_loss: 1.0020 - val_loss: 2.8186 - val_petal_width_output_loss: 0.9754 - val_petal_length_output_loss: 0.7314 - val_species_output_loss: 1.1118\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X, y = [y1, y2, y3], epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dat\n",
    "new_data = X[:3]\n",
    "pred = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.501481 ],\n",
       "        [2.7471495],\n",
       "        [2.3343337]], dtype=float32),\n",
       " array([[0.90332043],\n",
       "        [0.9480382 ],\n",
       "        [0.8646666 ]], dtype=float32),\n",
       " array([[0.35390592, 0.3807085 , 0.26538554],\n",
       "        [0.33470297, 0.38593957, 0.27935746],\n",
       "        [0.3568602 , 0.37842163, 0.26471815]], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4\n",
      "0.2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y1[0])\n",
    "print(y2[0])\n",
    "print(y3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 입력 모델\n",
    "- 가정 \n",
    "    - IRIS 꽃 데이터 + 꽃의 사진을 입력해서 꽃의 종류를 예측\n",
    "- X: 꽃 데이터, 꽃 사진\n",
    "- y: 꽃 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris 사진 대신 mnist 사진 사용 (예시니까...)\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (150, 28, 28))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, _), (_,_) = keras.datasets.mnist.load_data()\n",
    "X_train.shape\n",
    "X_img = X_train[:150]\n",
    "X_train.shape, X_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input을 2개 받는 모델 구현\n",
    "\n",
    "iris_info_tensor = layers.Input(shape=(4,)) # 꽃 정보\n",
    "x1 = layers.Dense(units=32, activation=\"relu\")(iris_info_tensor)\n",
    "x1 = layers.Dense(units=16, activation=\"relu\")(x1)\n",
    "\n",
    "iris_img_tensor = layers.Input(shape=(28, 28, 1))\n",
    "x2 = layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(iris_img_tensor)\n",
    "x2 = layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(x2)\n",
    "x2 = layers.MaxPooling2D(padding=\"same\")(x2)\n",
    "\n",
    "x3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x2)\n",
    "x3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x3)\n",
    "x3 = layers.MaxPooling2D(padding=\"same\")(x3)\n",
    "x3 = layers.GlobalAveragePooling2D()(x3)\n",
    "\n",
    "x4 = layers.concatenate([x1, x3])\n",
    "\n",
    "output_tensor = layers.Dense(units=3, activation=\"softmax\")(x4)\n",
    "\n",
    "model = models.Model([iris_info_tensor, iris_img_tensor],output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 32)   320         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 32)   9248        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 64)   36928       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           160         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80)           0           dense_19[0][0]                   \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            243         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 65,923\n",
      "Trainable params: 65,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.0359 - accuracy: 0.5185 - val_loss: 1.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.9617 - accuracy: 0.6222 - val_loss: 1.8222 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.9331 - accuracy: 0.7259 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.8746 - accuracy: 0.7259 - val_loss: 1.1192 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.8495 - accuracy: 0.7333 - val_loss: 1.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.8199 - accuracy: 0.7185 - val_loss: 1.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.7892 - accuracy: 0.6889 - val_loss: 1.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.7577 - accuracy: 0.7407 - val_loss: 1.2212 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.7283 - accuracy: 0.7407 - val_loss: 1.1765 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.7009 - accuracy: 0.7407 - val_loss: 1.0235 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.6723 - accuracy: 0.8074 - val_loss: 1.0189 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.6413 - accuracy: 0.7852 - val_loss: 0.9961 - val_accuracy: 0.0667\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.6169 - accuracy: 0.8889 - val_loss: 0.8932 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.5908 - accuracy: 0.8963 - val_loss: 0.9011 - val_accuracy: 0.2667\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5745 - accuracy: 0.8370 - val_loss: 1.0028 - val_accuracy: 0.0667\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.5430 - accuracy: 0.8667 - val_loss: 0.7479 - val_accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.5174 - accuracy: 0.8963 - val_loss: 1.0151 - val_accuracy: 0.1333\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.85 - 0s 97ms/step - loss: 0.4834 - accuracy: 0.8667 - val_loss: 1.0394 - val_accuracy: 0.1333\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.4566 - accuracy: 0.8963 - val_loss: 0.9775 - val_accuracy: 0.2667\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.4321 - accuracy: 0.8815 - val_loss: 1.0305 - val_accuracy: 0.1333\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.4055 - accuracy: 0.9037 - val_loss: 0.7996 - val_accuracy: 0.3333\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.4001 - accuracy: 0.9111 - val_loss: 0.8688 - val_accuracy: 0.3333\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3592 - accuracy: 0.9407 - val_loss: 0.8750 - val_accuracy: 0.3333\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3396 - accuracy: 0.9704 - val_loss: 0.9758 - val_accuracy: 0.2667\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.3174 - accuracy: 0.9333 - val_loss: 0.8510 - val_accuracy: 0.3333\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3088 - accuracy: 0.9481 - val_loss: 1.0164 - val_accuracy: 0.2667\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2678 - accuracy: 0.9778 - val_loss: 0.7787 - val_accuracy: 0.4667\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2596 - accuracy: 0.9630 - val_loss: 0.4367 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3643 - accuracy: 0.8370 - val_loss: 1.9949 - val_accuracy: 0.0667\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3231 - accuracy: 0.8889 - val_loss: 0.5191 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2931 - accuracy: 0.9407 - val_loss: 1.1706 - val_accuracy: 0.2667\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.2654 - accuracy: 0.9111 - val_loss: 0.8471 - val_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.3333\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1965 - accuracy: 0.9704 - val_loss: 1.0857 - val_accuracy: 0.2667\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1853 - accuracy: 0.9926 - val_loss: 1.0082 - val_accuracy: 0.3333\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1594 - accuracy: 1.0000 - val_loss: 1.5128 - val_accuracy: 0.2000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 0.1536 - accuracy: 0.9852 - val_loss: 0.8590 - val_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1392 - accuracy: 1.0000 - val_loss: 1.2653 - val_accuracy: 0.2667\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.1441 - accuracy: 1.0000 - val_loss: 1.3191 - val_accuracy: 0.2667\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.1885 - val_accuracy: 0.2667\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 1.4871 - val_accuracy: 0.2667\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0955 - accuracy: 0.9926 - val_loss: 0.9465 - val_accuracy: 0.4667\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.2667\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.8164 - val_accuracy: 0.2667\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 1.2306 - val_accuracy: 0.2667\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 1.7569 - val_accuracy: 0.2667\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.2667\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.4667\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 3.0676 - val_accuracy: 0.2000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0630 - accuracy: 0.9926 - val_loss: 1.4569 - val_accuracy: 0.2667\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 3.2913 - val_accuracy: 0.0667\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0831 - accuracy: 0.9926 - val_loss: 2.0289 - val_accuracy: 0.2667\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 94ms/step - loss: 0.1448 - accuracy: 0.9259 - val_loss: 0.3387 - val_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.98 - 0s 92ms/step - loss: 0.0806 - accuracy: 0.9852 - val_loss: 3.1796 - val_accuracy: 0.0667\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.1331 - accuracy: 0.9556 - val_loss: 0.8158 - val_accuracy: 0.4667\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0793 - accuracy: 0.9852 - val_loss: 1.6969 - val_accuracy: 0.2667\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 2.6124 - val_accuracy: 0.1333\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 0.5863 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.2667\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.2667\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.3333\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.6526 - val_accuracy: 0.2667\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.4000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2644 - val_accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.9105 - val_accuracy: 0.2667\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.4649 - val_accuracy: 0.4000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.6555 - val_accuracy: 0.3333\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5529 - val_accuracy: 0.3333\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.3333\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.3333\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.7066 - val_accuracy: 0.3333\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.3333\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.6823 - val_accuracy: 0.3333\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.7300 - val_accuracy: 0.3333\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.8137 - val_accuracy: 0.3333\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.8291 - val_accuracy: 0.3333\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.3333\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.3333\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7503 - val_accuracy: 0.3333\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6866 - val_accuracy: 0.3333\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.9923 - val_accuracy: 0.3333\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.8191 - val_accuracy: 0.3333\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.9598 - val_accuracy: 0.3333\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.8291 - val_accuracy: 0.3333\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7981 - val_accuracy: 0.3333\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 94ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7170 - val_accuracy: 0.3333\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.3333\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.9282 - val_accuracy: 0.3333\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.8621 - val_accuracy: 0.3333\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7697 - val_accuracy: 0.3333\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.9157 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10a0b705f40>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [X, X_img], y = y, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (((4,), (28, 28)), ()), types: ((tf.float64, tf.uint8), tf.int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices(((X, X_img), y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
