# 학습/테스트 데이터셋 분리

<img align="center" src="./images/image6.png" width=50%>

<br>
<br>


# 데이터셋
- ### Train 데이터셋 (훈련/학습 데이터셋)
    - 모델을 학습시킬 때 사용할 데이터셋.

<br>

- ### Validation 데이터셋 (검증 데이터셋)
    - Train set으로 학습한 모델의 성능을 측정하기 위한 데이터셋

<br>

- ### Test 데이터셋 (평가 데이터셋)
    - 모델의 성능을 최종적으로 측정하기 위한 데이터셋
    - **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용되어야 함!!**
        - 학습과 평가를 반복하다 보면 모델이 검증때 사용한 데이터셋에 과적합되어 새로운 데이터에 대한 성능이 떨어짐
        - 데이터셋을 train 세트, validation 세트, test 세트로 나눠 train 세트와 validation 세트로 모델을 최적화 한 뒤 마지막에 test 세트로 최종 평가

        <br>


        
>- 전체 데이터 X, y가 존재
>- Decision Tree라는 모델을 필요한 데이터에 맞게 fit하여 학습 후 예측

>- 전체 데이터로 train 데이터셋으로 하고 그 train 데이터 셋으로 모델을 평가한다는 의미는 문제를 푼 후에 정답을 맞추고 배운 문제를 가지고 다시 한번 평가한는 것!
>   - 학습할 때 이미 본 데이터이기 때문에 높은 정확도가 나옴 

>- 학습하지 않은 새로운 데이터를 사용해야 함
>- 새로운 데이터를 가지고 얼마만큼의 성능을 낼 것인지 확인을 해봐야하는데
나는 사실 지금은 새로운 데이터를 가지고 있지 않고 y값이 없다는 문제도 생김!
>   - 새로운 데이터에 역할을 하면서 정답(y)값도 있어야 하는 데이터가 필요
>- 지금 가진 데이터를 나누어 Train과 Test로 나눔!
>- 학습은 Train 데이터 셋으로만 이루어지고 학습할 때 사용하지 않은 Test Data는 성능을 파악할 때 사용


>- Train과 Test 데이터셋으로 나누어  
> 학습 <br>
> 예측 <br>
> 평가 (지표 : 정확도) 의 과정을 거침 <br>

>- 내가 만드는 모델은 목표한 정확도가 0.95 이상인데 평가를 해봤는데 0.85가 나옴
>   - 즉, 성능을 올려야함 
>- 데이터를 바꿀 수 없기 때문에 데이터 전처리나 하이퍼파라미터 수정 등을 통하여 학습과 예측 과정을 다시 반복!
>   - 두번째는 0.9 그럼 다시 수정해서 반복!
>   - 세번째에 0.95가 나오게 됨

>- 새로운 dataset으로 평가하고 싶은건데 이미 test set 여러번 사용, 
>   - 새로운 데이터라고 보기는 힘듦.
>- 모델을 수정하면서 test set에 맞추고 있고 이게 test/train 데이터를 나눈 목적이 없어지게 됨

>-  모델이 학습을 하는데 영향을 주지 않는 데이터여야하는데
수정을 하면서 test set의 정확도를 높이기 위해서 test set에 맞추는 경향이 생김!

>- 이 때, 수정한 모델을 평가하기 위하여 validation 데이터 셋을 만듦

  
<br>
<br>

- 코드 
```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=0)


X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state = 0)

```
